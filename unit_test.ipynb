{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "This file provides functionalities for unit testing<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import argparse\n", "import numpy as np\n", "import os.path\n", "from util import *\n", "from logistic_np import *\n", "import sys\n", "import pdb"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def testcase_check(your_arr, test_arr, testname, print_all, print_ind=None):\n", "    eps = 0.00001\n", "    if (type(your_arr) != type(test_arr)):\n", "        print(\"Testing %s: Failed. Your arr should be %s but it is %s instead.\" % (testname, type(test_arr), type(your_arr)))\n", "        return True\n", "    \n", "    if (your_arr.shape != test_arr.shape):\n", "        print(\"Testing %s: Failed. Your arr should have a shape of %s but its shape is %s instead.\" % (testname, test_arr.shape, your_arr.shape))\n", "        return True\n", "    if (np.sum((your_arr-test_arr)**2) < eps):\n", "        print(\"Testing %s: Passed.\" % testname)\n", "    else:\n", "        print(\"Testing %s: Failed.\" % testname)\n", "        if (print_all): \n", "            print(\"Your array is\")\n", "            print(your_arr)\n", "            print(\"\\nWhile it should be\")\n", "            print(test_arr)\n", "        else:\n", "            print(\"The first few rows of your array are\")\n", "            print(your_arr[print_ind, 0])\n", "            print(\"\\nWhile they should be\")\n", "            print(test_arr[print_ind, 0])\n", "        return True\n", "    print(\"----------------------------------------\")\n", "    return False"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def logistic_unit_test():\n", "    \"\"\"logistic_unit_test\n", "    Test most functions in the logistic regression assignment\n", "    \"\"\"\n", "    train_x, train_y, test_x, test_y = get_vehicle_data()\n", "    testcase = load_npy('./data/logistic_unittest.npy')\n", "    testcase = testcase[()]    \n", "    train_x = train_x[0:5]\n", "    train_y = train_y[0:5]\n", "     \n", "    train_x_norm1, _ = normalize_per_pixel(train_x, test_x)\n", "    # print(train_x_norm1)\n", "    if (testcase_check(train_x_norm1, testcase['train_x_norm1'], \"normalize_per_pixel\", True)):\n", "        return\n", "    \n", "    train_x, train_y, test_x, test_y = get_vehicle_data()\n", "    train_x = train_x[0:5]\n", "    train_y = train_y[0:5]\n", "    train_x_norm2, _ = normalize_all_pixel(train_x, test_x)\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    \n", "    if (testcase_check(train_x_norm2, testcase['train_x_norm2'], \"normalize_all_pixel\", True)):\n", "        return\n", "    train_x = reshape2D(train_x)\n", "    if (testcase_check(train_x, testcase['train_x2D'], \"reshape2D\", True)):\n", "        return\n", "    train_x = add_one(train_x)\n", "    if (testcase_check(train_x, testcase['train_x1'], \"add_one\", True)):\n", "        return\n", "     \n", "    train_x = testcase['train_x1']\n", "    learning_rate = 0.001\n", "    momentum_rate = 0.9\n", "    for i in range(10): \n", "        test_dict = testcase['output'][i]\n", "        classifier = LogisticClassifier((train_x.shape[1], 1))\n", "        classifier.w = test_dict['w']\n", "        \n", "        y_hat = classifier.feed_forward(train_x)\n", "        if(testcase_check(y_hat, test_dict['y_hat'], \"feed_forward %d\" % (i+1), True)):\n", "            return\n", "        loss = classifier.compute_loss(train_y, y_hat)\n", "        if(testcase_check(loss, test_dict['loss'], \"compute_loss %d\" % (i+1), True)):\n", "            return\n", "        grad = classifier.get_grad(train_x, train_y, y_hat)\n", "        if(testcase_check(grad, test_dict['grad'], \"get_grad %d\" % (i+1), True)):\n", "            return\n", "        classifier.update_weight(grad, 0.001)\n", "        if(testcase_check(classifier.w, test_dict['w_1'], \"update_weight %d\" % (i+1), True)):\n", "            return\n", "        \n", "        momentum = np.ones_like(test_dict['grad'])\n", "        classifier.update_weight_momentum(grad, learning_rate, momentum, momentum_rate)\n", "        if(testcase_check(classifier.w, test_dict['w_2'], \"update_weight_momentum %d\" % (i+1), True)):\n", "            return\n", " \n", "        testcase['output'].append(test_dict)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def softmax_unit_test():\n", "    \"\"\"softmax_unit_test\n", "    Test most functions in the softmax regression assignment\n", "    \"\"\"\n", "    \n", "    train_x, train_y, _, _, _, _ = get_mnist_data()\n", "    train_x = train_x[0:5, :]\n", "    train_y = train_y[0:5]\n", "    val_x   = train_x[5:10]\n", "    test_x  = train_x[10:15]\n", "    testcase = load_npy('./data/softmax_unittest.npy')\n", "    testcase = testcase[()]    \n", "    train_x, _, _ = normalize(train_x, val_x, test_x)\n", "    # print(train_y.shape)\n", "    if (testcase_check(train_x, testcase['train_x_norm'], \"normalize\", True)):\n", "        return\n", "    train_y = create_one_hot(train_y)\n", "    if (testcase_check(train_y, testcase['one_hot'], \"create_one_hot\", True)):\n", "        return\n", "    learning_rate = 0.001\n", "    momentum_rate = 0.9\n", "    for i in range(10): \n", "        test_dict = testcase['output'][i]\n", "        classifier = SoftmaxClassifier((train_x.shape[1], 10))\n", "        classifier.w = test_dict['w']\n", "        \n", "        y_hat = classifier.feed_forward(train_x)\n", "        loss = classifier.compute_loss(train_y, y_hat)\n", "        grad = classifier.get_grad(train_x, train_y, y_hat) \n", "        if (testcase_check(y_hat, test_dict['y_hat'], \"feed_forward / softmax\", True)):\n", "            return\n", "   \n", "        if (testcase_check(loss, test_dict['loss'], \"compute_loss\", True)):\n", "            return\n", "        if (testcase_check(grad, test_dict['grad'], \"get_grad\", True)):\n", "            return "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    parser = argparse.ArgumentParser(description='Perform unitest on numpy logistic regression or softmax regression')\n", "    parser.add_argument('choice', nargs='?', type=int, help='logistic or softmax', default=-1)\n", "    parser.add_argument('sol', nargs='?', type=str, help='', default='')\n", "    args = parser.parse_args()\n", "    choice = args.choice\n", "    sol = args.sol\n", "    if (choice == -1):\n", "        choice = input('Please enter 0 for logistic or 1 for softmax: ')\n", "        if(sys.version_info[0] == 3):\n", "            choice = int(choice)\n", "    np.set_printoptions(precision=3, edgeitems=2)\n", "    if (choice == 0):\n", "        #if (sol.lower() == 'sol'):\n", "            #from logistic_np_sol import *\n", "        #else:\n", "        from logistic_np import *\n", "        print('Running logistic np unit test...')\n", "        logistic_unit_test() \n", "    elif (choice == 1):\n", "        #if (sol.lower() == 'sol'):\n", "            #from softmax_np_sol import *\n", "        #else:\n", "        from softmax_np import *\n", "        print('Running logistic np unit test...')\n", "        softmax_unit_test()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}